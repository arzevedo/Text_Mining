---
title: "A text analysis of Chernobyl's screenplay"
author: "Arthur Azevedo"
date: "08/06/2019"
output: rmarkdown::github_document
---

```{r setup and libraries, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pdftools)
library(tidytext)
library(ggraph)
library(igraph)
```

# First things first
I have to tell you right away that I loved the series the political, horror and drama were entangled in a way that amazed me so much that I couldn't wait for the next episode.
When I saw Mazin on twitter saying that he gave open access to the screenplay i had to have a look.
One last thing. This code/text may contain spoilers. I will give some warning before dropping something major to the plot. But be warned.

So... let's get the data

## Extracting the data

I'll download the screenplays for reproducibility purposes. I made a loop in the `download.file` function for every episode.
```{r Read and Download, message=FALSE}
episode_name <- c("11_23_45", "2Please-Remain-Calm", "3Open-Wide-O-Earth",
                  "4The-Happiness-Of-All-Mankind", "5Vichnaya-Pamyat")

for(episode in episode_name){
  download.file(
    paste0("https://johnaugust.com/wp-content/uploads/2019/06/Chernobyl_Episode-",
           episode, ".pdf"), 
    paste0(episode, ".pdf"), mode = "wb"
  )
}
```

## Assembling 
The .pdf format is pleasant to work with text. Using the `pdf_text` function from the `pdftools` package we can assemble the text into lists. Then we merge all in a _tibble_.
```{r Assemble}

pdf_names <- paste0(episode_name, ".pdf")
raw_text <- map(pdf_names, pdf_text)

chernobyl <- tibble(episode = pdf_names, text = raw_text) %>% 
  mutate(
    episode =
      case_when(
        .$episode == "11_23_45.pdf"                      ~ "1:23:45",
        .$episode == "2Please-Remain-Calm.pdf"           ~ "Please Remain Calm",
        .$episode == "3Open-Wide-O-Earth.pdf"            ~ "Open Wide, O Earth",
        .$episode == "4The-Happiness-Of-All-Mankind.pdf" ~ "The Happiness Of All Mankind",
        TRUE           ~ "Vichnaya Pamyat"
      )
  )

```

## Tidying
[The _tidy_ format](https://www.tidyverse.org/learn/) makes easy handling data. Julia Silge and David Robinson defining tidy text format as being a table with one token per row. A token is a meaningful unit of text.
With all that said, let's travel to the north of Ukraine.
```{r tidying}
chernobyl_tidy <- chernobyl %>% 
  unnest %>% # pdfs_text is a list
  unnest_tokens(word, text, strip_numeric = TRUE) %>% 
  mutate(episode = factor(episode,
                          levels = c("1:23:45", "Please Remain Calm", "Open Wide, O Earth",
                                     "The Happiness Of All Mankind", "Vichnaya Pamyat")))
```

## Filtering
Create a _data set_ without stop words. 
```{r filter}
chernobyl_tidy_fil <- chernobyl_tidy %>% 
  anti_join(stop_words)

characters <- c("legasov", "shcherbina", "dyatlov", "bacho", "pavel",
                "shcherbina", "khomyuk", "toptunov", "akimov", "lyudmilla",
                "bryukhanov", "tarakanov", "fomin", "sitnikov", "gorbachev",
                "vasily", "pikalov", "dmitri", "yuvchenko", "gorbachenko",
                "stolyarchuk", "boris", "charkov", "vetrova", "shadov",
                "garo", "stepashin")
```

## Ploting Frequency
```{r Most frequent word, fig.align="center"}
reorder_within <- function(x, by, within, fun = mean, sep = "___", ...) {
  new_x <- paste(x, within, sep = sep)
  stats::reorder(new_x, by, FUN = fun)
}
scale_x_reordered <- function(..., sep = "___") {
  reg <- paste0(sep, ".+$")
  ggplot2::scale_x_discrete(labels = function(x) gsub(reg, "", x), ...)
}
chernobyl_tidy_fil %>% 
  group_by(episode, word) %>% 
  count(sort = TRUE) %>% 
  filter(!word %in% characters) %>% 
  group_by(episode) %>% 
  top_n(10, n) %>%
  ungroup() %>%
  ggplot(aes(reorder_within(word, n, episode), n))+
  geom_col(fill = "#0D0D0D")+
  scale_x_reordered()+
  facet_wrap(~episode, scales = "free_y")+
  coord_flip()+
  theme_minimal()+theme(legend.position = "none")+
  labs(caption = "Viz: @RiversArthur \nData: https://johnaugust.com ",
       x = NULL, y = NULL, title = "Most frequent words",
       subtitle = "Without stop words and characters names")+
  theme(panel.background = element_rect(fill = "#F2E205"), strip.text = element_text(size = 13),
        panel.grid.major.y = element_blank(),
        axis.text.y = element_text(size = 10),
        plot.background = element_rect(fill = "#F2E205", color = "#F2E205"))

```



## TF-IDF

```{r TF-IDF}
chernobyl_tidy_fil_per_epi <- chernobyl_tidy_fil %>% 
  count(episode, word, sort = TRUE) %>% 
  ungroup()

total_words <- chernobyl_tidy_fil_per_epi %>% 
  group_by(episode) %>% 
  summarise(total = sum(n))

chernobyl_tidy_fil_per_epi <- left_join(chernobyl_tidy_fil_per_epi, total_words)

chernobyl_tidy_fil_per_epi <- chernobyl_tidy_fil_per_epi %>%
  bind_tf_idf(word, episode, n )

chernobyl_tidy_fil_per_epi %>% 
  select(-total) %>% 
  arrange(desc(x = tf_idf))
chernobyl_tidy_fil_per_epi %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  group_by(episode) %>%
  top_n(10) %>% 
  ungroup %>% 
  ggplot(aes(word, tf_idf, fill = episode)) +
  geom_col(show.legend = FALSE, fill = "#4C1706")+
  facet_wrap(~episode, ncol = 5, scales = "free") + 
  coord_flip()
```
